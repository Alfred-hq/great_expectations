from __future__ import annotations

from typing import TYPE_CHECKING, Sequence, Union

from pydantic import BaseModel

from great_expectations.validator.metric_configuration import MetricConfiguration
from great_expectations.validator.metrics_calculator import MetricsCalculator

if TYPE_CHECKING:
    from typing_extensions import TypeAlias

    from great_expectations.datasource.fluent import BatchRequest, DataAsset
    from great_expectations.datasource.fluent.interfaces import Batch


class Metric(BaseModel):
    name: str
    placeholder_value: str  # TODO: Add value model and replace this
    # TODO: Add fields, config


class Metrics(BaseModel):
    """Collection of Metric objects."""

    metrics: Sequence[Metric]
    # TODO: Add fields, config


CloudStorableTypes: TypeAlias = Union[Metrics,]  # TODO: are there better approaches?


class CloudStoreBackend:  # TODO: Name this better
    pass
    # TODO: Add methods
    # TODO: Investigate - If only implementing Create, can we use existing?

    def create(
        self, value_type: CloudStorableTypes, value: CloudStorableTypes
    ) -> None:  # TODO: How to annotate?
        print(
            f"Creating item of type {value_type.__name__} in CloudStoreBackend - sending a POST REST API request to the cloud."
        )
        print(value)


class ColumnDescriptiveMetricsStore:
    pass
    # TODO: Add methods

    def __init__(self, backend: CloudStoreBackend):
        self._backend = backend

    def create(self, metrics: Metrics) -> None:
        print("Creating metric in ColumnDescriptiveMetricsStore")
        self._backend.create(
            value_type=Metrics, value=metrics
        )  # TODO: How to annotate/implement?


# TODO: How does agent pass batch request? Assuming batch_request is necessary to specify a specific batch for introspection
#  rather than just the data asset as a full batch.
def inspect_asset(asset: DataAsset, batch_request: BatchRequest | None) -> Metrics:
    """Inspect a DataAsset and return Metrics."""
    print("This method would be invoked via an AgentAction")
    print(f"Inspecting data asset: {asset.name}")
    print(
        "NOTE: Here is where we can use things like DomainBuilder and MetricCalculator to calculate metrics"
    )
    if batch_request is None:
        batch_request = asset.build_batch_request()

    batch = _get_batch(asset, batch_request)

    # TODO: Use DomainBuilder and MetricCalculator to generate.
    metrics = _get_metrics_to_describe_batch(batch)
    return metrics


# TODO: Alternative approach - use an Inspector class:
# class AssetInspector:  # TODO: Name this better, or is this just a single method instead of class?
#     pass
#     # TODO: Add methods
#
#     def __init__(self, asset: DataAsset) -> None:
#         self._asset = asset
#
#     def inspect_batch(
#         self, batch_request: BatchRequest
#     ) -> Metrics:  # TODO: Should this take a batch instead of a batch request?
#         print("This method would be invoked via an AgentAction")
#         print(
#             f"Inspecting data asset: {self._asset.name} with batch request:\n{batch_request}"
#         )
#         print(
#             "NOTE: Here is where we can use things like DomainBuilder and MetricCalculator to calculate metrics"
#         )
#         metrics = Metrics(
#             metrics=[Metric(name="my_metric")]
#         )  # TODO: Use DomainBuilder and MetricCalculator to generate.
#         return metrics


def _get_batch(asset: DataAsset, batch_request: BatchRequest) -> Batch:
    batch_list = asset.get_batch_list_from_batch_request(batch_request=batch_request)
    if len(batch_list) > 1:
        # TODO: Better warning that we are only getting the first batch if there are multiple.
        print(
            "WARNING: More than one batch was returned. Only the first batch will be used."
        )
    batch = batch_list[0]
    # TODO: Error if no batches.
    return batch


def _get_domains(batch: Batch):
    pass
    # TODO: Implement
    # TODO: Do we need a rule as well?
    # domain_builder.get_domains()


def _convert_metrics_dict_to_metrics_object(raw_metrics: dict) -> Metrics:
    """Convert a dict of metrics to a Metrics object.

    Args:
        raw_metrics: Dict of metrics, where keys are metric names and values are metrics.
            Generated by the MetricsCalculator.

    Returns:
        Metrics object.
    """
    # TODO: Add the rest of the metric fields, convert value to Value object:
    metric_objs = [
        Metric(name=metric_name, placeholder_value=str(metric))
        for metric_name, metric in raw_metrics.items()
    ]
    return Metrics(metrics=metric_objs)


def _get_metrics_to_describe_batch(batch: Batch) -> Metrics:
    # TODO: Why do we typically get the execution engine from batch.data?
    #  Shouldn't it be from the datasource?
    metric_calculator = MetricsCalculator(execution_engine=batch.data.execution_engine)

    # TODO: Get domain_kwargs from DomainBuilder for columns.

    # TODO: Implement more than just table.head:

    metrics_to_get = [
        MetricConfiguration(
            metric_name="table.head",
            metric_domain_kwargs={"batch_id": batch.id},
            metric_value_kwargs={
                "n_rows": 5,
                # "fetch_all": fetch_all,  # TODO: Is default already false?
            },
        ),
        MetricConfiguration(
            metric_name="table.row_count",
            metric_domain_kwargs={"batch_id": batch.id},
            metric_value_kwargs={},
        ),
    ]

    raw_metrics = metric_calculator.get_metrics(
        {metric_config.metric_name: metric_config for metric_config in metrics_to_get}
    )
    metrics = _convert_metrics_dict_to_metrics_object(raw_metrics=raw_metrics)
    return metrics
